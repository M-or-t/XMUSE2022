import pandas as pd
import numpy as np
from collections import Counter
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors



# 1. 加载数据集（使用Iris数据集作为例子）
iris = pd.read_csv('data\iris.csv')  #读取数据文件
X = iris.iloc[:, :4].values  #获得样本数据
y = iris.iloc[:,-1].values   #获得样本的类标签

# 2. 获得PCA降维到2维后的数据,保存在data_pca中
#补充你的代码


print('PCA降维:\n',data_pca)





# 3. KNN算法类定义
class KNN:
    def __init__(self, k=3):
        self.k = k  # 设置邻居数目    

    # 训练模型（存储训练数据）
    def fit(self, X_train, y_train):
        self.X_train = X_train
        self.y_train = y_train

    # 计算欧氏距离
    def euclidean_distance(self, point1, point2):
        return np.sqrt(np.sum((point1 - point2) ** 2))

    # 预测一组数据点的类别
    def predict(self, X_test):
        predictions = []

        #补充你的代码
        
        return np.array(predictions)


# 4. 数据集划分，80%训练集，20%测试集
X_train, X_test, y_train, y_test = train_test_split(data_pca, y, test_size=0.2, random_state=42)

# 5. 初始化KNN模型并训练
knn = KNN(k=3)
knn.fit(X_train, y_train)

# 6. 对测试集进行预测
y_pred = knn.predict(X_test)

# 7. 打印预测结果
print("预测结果：", y_pred)
print("真实标签：", y_test)



from sklearn.metrics import accuracy_score, classification_report

# 8. 评估分类器的性能
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=np.unique(y)))



# 9. 可视化

# 创建网格用于绘制决策边界
x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1
y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                     np.arange(y_min, y_max, 0.1))

label_map = {'setosa': 0, 'versicolor': 1, 'virginica': 2}

# 批量预测网格上的类别
grid_points = np.c_[xx.ravel(), yy.ravel()]
Z = knn.predict(grid_points)
Z_mapped = np.vectorize(label_map.get)(Z)  # 映射为数字标签

# 将 Z 数组重塑为网格形状
Z_mapped = Z_mapped.reshape(xx.shape)

# 使用 label_map 将 y_train 和 y_test 映射为数字
y_train_mapped = np.vectorize(label_map.get)(y_train)
y_test_mapped = np.vectorize(label_map.get)(y_test)

# 自定义颜色映射，只使用3种颜色，直接使用颜色名称
colors = ['blue', 'orange', 'green']  # Setosa, Versicolor, Virginica
cmap = mcolors.ListedColormap(colors)

# 绘制决策边界
plt.contourf(xx, yy, Z_mapped, alpha=0.3, cmap=cmap, levels=np.arange(-0.5, 3.5, 1))

# 绘制训练数据点
scatter_train = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train_mapped, marker='o', edgecolor='k', s=60, cmap=cmap, label='Train data')

# 绘制测试数据点
scatter_test = plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test_mapped, marker='s', edgecolor='k', s=60, cmap=cmap, label='Test data')

# 设置坐标轴标签和标题
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('KNN Decision Boundary (K=3)')

# 自动生成图例
plt.legend()

# 获取 colorbar
cbar = plt.colorbar(scatter_train, label='Classes')

# 设置色条的刻度为三个类别，分别为 0, 1, 2（对应 Setosa, Versicolor, Virginica）
cbar.set_ticks([0, 1, 2])  # 设置为三个类别的刻度
cbar.set_ticklabels(['Setosa', 'Versicolor', 'Virginica'])  # 设置对应的标签

# 显示图形
plt.show()

