





import pandas as pd
import numpy as np

iris = pd.read_csv('data\iris.csv')  #读取数据文件

data = iris.iloc[:, :4]  #获得样本数据

target = iris.iloc[:,-1].values   #获得样本的类标签


#标准化处理数据




#计算数据集的协方差矩阵







#求解协方差矩阵的特征值及相应的正交化单位特征向量




#将特征值和特征向量对应起来，按照特征值大小排序




#确定主成分的贡献率




#组合第一和第二特征向量实现降维
#保存在data_pca中




#可视化降维后的数据分布




#采用熵作为不纯性度量的决策树分类器
import numpy as np

class DecisionTree:
    def __init__(self):
        pass
    
    def entropy(self, y):      #计算熵
        classes = np.unique(y)
        entropy = 0
        for cls in classes:
            p_cls = np.mean(y == cls)
            entropy += -p_cls * np.log2(p_cls)
        return entropy
    
    def information_gain(self, X, y, feature_idx, threshold):     #计算信息增益
        parent_entropy = self.entropy(y)
        left_idxs = X[:, feature_idx] < threshold
        right_idxs = ~left_idxs
        if np.sum(left_idxs) == 0 or np.sum(right_idxs) == 0:
            return 0
        left_entropy = self.entropy(y[left_idxs])
        right_entropy = self.entropy(y[right_idxs])
        child_entropy = np.mean(left_idxs) * left_entropy + np.mean(right_idxs) * right_entropy
        return parent_entropy - child_entropy
    
    def find_best_split(self, X, y):     #找出最优划分
        best_gain = 0
        best_feature_idx = None
        best_threshold = None
        for feature_idx in range(X.shape[1]):
            thresholds = np.unique(X[:, feature_idx])
            for threshold in thresholds:
                gain = self.information_gain(X, y, feature_idx, threshold)
                if gain > best_gain:
                    best_gain = gain
                    best_feature_idx = feature_idx
                    best_threshold = threshold
        return best_feature_idx, best_threshold
    
    def fit(self, X, y):             #拟合数据
        if len(np.unique(y)) == 1:
            return {'class': y[0]}
        else:
            best_feature_idx, best_threshold = self.find_best_split(X, y)
            left_idxs = X[:, best_feature_idx] < best_threshold
            right_idxs = ~left_idxs
            tree = {
                'feature_idx': best_feature_idx,
                'threshold': best_threshold,
                'left': self.fit(X[left_idxs], y[left_idxs]),
                'right': self.fit(X[right_idxs], y[right_idxs])
            }
            return tree
    
    def predict_sample(self, sample, tree):
        if 'class' in tree:
            return tree['class']
        else:
            if sample[tree['feature_idx']] < tree['threshold']:
                return self.predict_sample(sample, tree['left'])
            else:
                return self.predict_sample(sample, tree['right'])
    
    def predict(self, X, tree):
        return [self.predict_sample(sample, tree) for sample in X]





from sklearn.model_selection import train_test_split


# 将PCA处理过的数据分成训练数据和测试数据,80%用于训练，20%用于测试
X_train, X_test, y_train, y_test = train_test_split(data_pca, target, test_size=0.2, random_state=42)

dt = DecisionTree()
tree = dt.fit(X_train, y_train)   #后续用graphviz对其可视化

#输出训练好的树
print(tree)

# 预测
y_pred = dt.predict(X_test,tree)




from sklearn.metrics import accuracy_score, classification_report

# 评估分类器的性能
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=np.unique(target)))





import os
from import Digraph

# 设置Graphviz的安装路径
# 请将路径替换为你的Graphviz安装路径
# 例如：graphviz_path = r'C:\Program Files\Graphviz\bin'
graphviz_path = r'C:\Program Files\Graphviz\bin'

# 将Graphviz的安装路径添加到系统的PATH环境变量中
os.environ["PATH"] += os.pathsep + graphviz_path




#将决策树可视化
import graphviz

def visualize_tree(tree_data, parent=None, node_name=None):
    if node_name is None:
        node_name = str(tree_data['feature_idx']) + ' <= ' + str(tree_data['threshold'])
    if 'class' in tree_data:
        class_label = tree_data['class']
        dot.node(node_name, class_label, shape='box')
    else:
        feature_idx = tree_data['feature_idx']
        threshold = tree_data['threshold']
        dot.node(node_name, f"X[{feature_idx}] <= {threshold}")
        left_child_name = f"{node_name}_left"
        right_child_name = f"{node_name}_right"
        dot.edge(node_name, left_child_name, label="Yes")
        dot.edge(node_name, right_child_name, label="No")
        visualize_tree(tree_data['left'], node_name, left_child_name)
        visualize_tree(tree_data['right'], node_name, right_child_name)

dot = graphviz.Digraph(graph_attr={'size': '8,8'})  # 设置图形大小
visualize_tree(tree)
display(dot)




