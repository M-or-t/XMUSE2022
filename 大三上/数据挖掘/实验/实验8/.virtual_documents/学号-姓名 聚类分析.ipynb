














import numpy as np
from numpy import *


#1. 加载并输出数据
def loadDataSet(fileName):
    data = np.loadtxt(fileName, delimiter='\t')
    return data
data = loadDataSet('dataSet.txt')
x = data[:,0]
y = data[:,1]

print(data[:10])  #输出前10个


#2. 对数据进行可视化
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.title('Original data')
plt.xlabel('x')
plt.ylabel('y')
plt.scatter(x,y,alpha=0.5,c='blue', label='Data Points')
plt.grid(True)


#3. 计算欧氏距离
def distEclid(vecA, vecB):
    return sqrt(sum(power(vecA - vecB, 2)))    #计算两个对象之间的距离


#4. 随机选取k个质心，返回的数组中保存有初始质心的坐标
def randCent(dataSet, k):
    n = np.shape(dataSet)[1]
    centroids = np.zeros((k, n))  # 总共k个质心，每个质心有n个坐标值
 
    #补充你的代码

    return centroids

#输出随机初始质心
centroids = randCent(data, 4) 
print("Initial random centroids:\n", centroids)  


#5. 对随机初始质心进行可视化
plt.figure(figsize=(8, 6))
plt.title('Original data and random centers')
plt.xlabel('x')
plt.ylabel('y')
plt.scatter(x,y,alpha=0.5,c='blue', label='Data Points')
plt.scatter(centroids[:,0], centroids[:,1], color='r',s=150,marker='+',label='Centers')
plt.legend()
plt.grid(True)


#6. 使用𝐾-means++初始化质心
def initialize_centers(X, k, seed=50):
    if seed is not None:
        np.random.seed(seed)  # 设置随机种子，保证随机性一致
    
    centers = [X[np.random.randint(X.shape[0])]]  # 随机选择第一个中心
    while len(centers) < k:
        # 计算到最近中心的平方距离
        dist_sq = np.array([min(np.linalg.norm(x - c)**2 for c in centers) for x in X])
        probs = dist_sq / dist_sq.sum()  # 计算概率
        cumulative_probs = probs.cumsum()
        r = np.random.rand()
        # 按累计概率选择下一个中心
        for j, p in enumerate(cumulative_probs):
            if r < p:
                centers.append(X[j])
                break
    return np.vstack(centers)

k = 4  # 设定中心点数量
createCent = initialize_centers(data, k)
print("Created centroids:\n", createCent) 



#7. 对创建的初始质心进行可视化
plt.figure(figsize=(8, 6))
plt.title('Original data and created centers')
plt.xlabel('x')
plt.ylabel('y')
plt.scatter(x,y,alpha=0.5,c='blue', label='Data Points')
plt.scatter(createCent[:,0], createCent[:,1], color='g',s=150,marker='+',label='Centers')
plt.legend()
plt.grid(True)


#8. k-means 聚类算法
def kMeans(dataSet, k, distMeans=distEclid, createCent=randCent):
    m, n = dataSet.shape
    clusterAssment = np.zeros((m, 2))   # 用于存放该样本属于哪簇及到质心距离
    centroids = createCent(dataSet, k)  # 质心初始化

    #补充你的代码
    
    return centroids, clusterAssment

#输出聚类结果
centroids, clusterAssment = kMeans(data, 4, distEclid, initialize_centers) 
print("Final centroids:\n", centroids)  #最终的聚类中心
print("Cluster assignment:\n", clusterAssment)  #每个样本被分配的簇标号，以及到聚类中心的距离


#9. 对聚类结果进行可视化
plt.figure(figsize=(8, 6))
plt.title('Clustering results and final centers')
plt.xlabel('x')
plt.ylabel('y')
plt.scatter(x,y,alpha=0.5,c=clusterAssment[:,0], label='Data Points')
plt.scatter(centroids[:,0], centroids[:,1], color='r',s=150,marker='+',label='Centers')
plt.legend()
plt.grid(True)


#10. 计算轮廓系数指标
from sklearn.metrics import silhouette_score
score = silhouette_score(data, clusterAssment[:,0] , metric='euclidean')
score



